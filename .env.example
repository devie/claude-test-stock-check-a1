# ── AI Analysis provider (default: groq) ─────────────────────────────────────
# Pilihan: groq | ollama | anthropic | openai
LLM_PROVIDER=groq

# Groq — gratis, daftar di https://console.groq.com/keys
GROQ_API_KEY=gsk_...

# Anthropic (berbayar) — https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-...

# Ollama (lokal, gratis, tidak perlu key) — https://ollama.ai/
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2:1b     <- opsional, ganti model
# OLLAMA_MODEL=llama3.2:1b  <- model khusus fallback Ollama (default: llama3.2:1b)
#                              Gunakan llama3.2:1b (1.3 GB) untuk RAM terbatas (<4 GB)
#                              Gunakan llama3.2 (2.0 GB) jika RAM >= 6 GB

# Auto-fallback: jika Groq rate-limited / diblok VPN, app otomatis retry ke Ollama lokal.
# Pastikan Ollama sudah berjalan: ollama serve
# dan model sudah di-pull: ollama pull llama3.2:1b

# Override model default untuk provider manapun (opsional)
# LLM_MODEL=llama-3.1-70b-versatile
